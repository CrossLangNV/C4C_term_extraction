version: '3'

services:
  #  gq_bert:
  #    build: ./question_generator
  #    ports:
  #      - "7500:5000"
  ##    runtime: nvidia
  #    environment:
  #      - "DEVICE=cuda:0"
  #      - "NVIDIA_VISIBLE_DEVICES=0"
  #    volumes:
  #      - "./question_generator:/project"

  # TODO This does not seem to be working at the moment.
  c4c_term_extraction:
    build:
      context: .
      dockerfile: ./Dockerfile
      args:
        - "MODEL_DIR=MODELS/model_MULTI_DISTILBERT_unfreeze_last_layers_5epoch_C4C_adresses"
    ports:
      - "7001:5001"
    volumes:
      - "./src:/work/src"
      - "./media:/work/media"
      - "./question_generator:/work/question_generator"
    #    runtime: nvidia
    #    environment:
    #      - "DEVICE=cuda:0"
    #      - "NVIDIA_VISIBLE_DEVICES=0"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]

  python_contact_info:
    build:
      context: src/contact_info
      dockerfile: Dockerfile
    image: "python_contact_info"
    ports:
      - "7002:5001"
    volumes:
      - "./src:/work/src"

  contact_info_api:
    build:
      context: ./src/contact_info/api
      dockerfile: ./Dockerfile
    ports:
      - "7003:1234"
    volumes:
      - "./src:/work/src"
    depends_on:
      - python_contact_info
